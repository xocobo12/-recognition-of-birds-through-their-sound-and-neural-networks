{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing: Especies 3sg\\American Oystercatcher\n"
     ]
    },
    {
     "ename": "NoBackendError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoBackendError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-46286dfafa77>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[0msave_mfcc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mJSON_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_segments\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-46286dfafa77>\u001b[0m in \u001b[0;36msave_mfcc\u001b[1;34m(dataset_path, json_path, num_mfcc, n_fft, hop_length, num_segments)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[1;31m# load audio file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[0mfile_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 \u001b[0msignal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSAMPLE_RATE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[1;31m# process all segments of audio file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;31m# All backends failed!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNoBackendError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoBackendError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import math\n",
    "import librosa\n",
    "\n",
    "DATASET_PATH = \"Especies 3sg\"\n",
    "JSON_PATH = \"data_10_3sg.json\"\n",
    "SAMPLE_RATE = 22050\n",
    "TRACK_DURATION = 3 # measured in seconds\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\n",
    "\n",
    "\n",
    "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=6):\n",
    "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n",
    "        :param dataset_path (str): Path to dataset\n",
    "        :param json_path (str): Path to json file used to save MFCCs\n",
    "        :param num_mfcc (int): Number of coefficients to extract\n",
    "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
    "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
    "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "    # dictionary to store mapping, labels, and MFCCs\n",
    "    data = {\n",
    "        \"mapping\": [],\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "    }\n",
    "\n",
    "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
    "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
    "\n",
    "    # loop through all genre sub-folder\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "\n",
    "        # ensure we're processing a genre sub-folder level\n",
    "        if dirpath is not dataset_path:\n",
    "\n",
    "            # save genre label (i.e., sub-folder name) in the mapping\n",
    "            semantic_label = dirpath.split(\"/\")[-1]\n",
    "            data[\"mapping\"].append(semantic_label)\n",
    "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
    "\n",
    "            # process all audio files in genre sub-dir\n",
    "            for f in filenames:\n",
    "\n",
    "\t\t# load audio file\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
    "\n",
    "                # process all segments of audio file\n",
    "                for d in range(num_segments):\n",
    "\n",
    "                    # calculate start and finish sample for current segment\n",
    "                    start = samples_per_segment * d\n",
    "                    finish = start + samples_per_segment\n",
    "\n",
    "                    # extract mfcc\n",
    "                    mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "                    mfcc = mfcc.T\n",
    "\n",
    "                    # store only mfcc feature with expected number of vectors\n",
    "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
    "                        data[\"mfcc\"].append(mfcc.tolist())\n",
    "                        data[\"labels\"].append(i-1)\n",
    "                        print(\"{}, segment:{}\".format(file_path, d+1))\n",
    "\n",
    "    # save MFCCs to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)              \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
